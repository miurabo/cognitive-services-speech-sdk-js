{"version":3,"sources":["src/common.speech/SpeakerServiceRecognizer.ts"],"names":[],"mappings":"AAIA,OAAO,EAEH,YAAY,EAIf,MAAM,mBAAmB,CAAC;AAE3B,OAAO,EAAE,uBAAuB,EAAE,MAAM,gCAAgC,CAAC;AACzE,OAAO,EACH,qBAAqB,EACrB,kBAAkB,EAClB,wBAAwB,EACxB,iBAAiB,EAKpB,MAAM,gBAAgB,CAAC;AACxB,OAAO,EAIH,qBAAqB,EACxB,MAAM,WAAW,CAAC;AACnB,OAAO,EAAE,eAAe,EAAE,MAAM,mBAAmB,CAAC;AACpD,OAAO,EAAE,kBAAkB,EAAE,MAAM,sBAAsB,CAAC;AAC1D,OAAO,EAAE,gBAAgB,EAAE,MAAM,oBAAoB,CAAC;AACtD,OAAO,EAAE,uBAAuB,EAAE,MAAM,oCAAoC,CAAC;AAY7E,qBAAa,wBAAyB,SAAQ,qBAAqB;IAC/D,OAAO,CAAC,qBAAqB,CAAoB;IACjD,OAAO,CAAC,sBAAsB,CAAe;IAC7C,OAAO,CAAC,kBAAkB,CAAqC;IAC/D,OAAO,CAAC,gBAAgB,CAA0B;gBAG9C,cAAc,EAAE,eAAe,EAC/B,iBAAiB,EAAE,kBAAkB,EACrC,WAAW,EAAE,YAAY,EACzB,gBAAgB,EAAE,gBAAgB,EAClC,UAAU,EAAE,iBAAiB;IAQjC,SAAS,CAAC,2BAA2B,CAAC,iBAAiB,EAAE,uBAAuB,GAAG,OAAO,CAAC,OAAO,CAAC;IAwCnG,SAAS,CAAC,iBAAiB,CACvB,SAAS,EAAE,MAAM,EACjB,SAAS,EAAE,MAAM,EACjB,kBAAkB,EAAE,kBAAkB,EACtC,SAAS,EAAE,qBAAqB,EAChC,KAAK,EAAE,MAAM,GAAG,IAAI;IAuBX,oBAAoB,CAAC,KAAK,EAAE,uBAAuB,GAAG,OAAO,CAAC,wBAAwB,CAAC;YAiDtF,oBAAoB;YAMpB,sBAAsB;IAUpC,OAAO,CAAC,qBAAqB;CAUhC","file":"SpeakerServiceRecognizer.d.ts","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nimport { ReplayableAudioNode } from \"../common.browser/Exports\";\nimport {\n    Deferred,\n    IAudioSource,\n    IAudioStreamNode,\n    IConnection,\n    MessageType,\n} from \"../common/Exports\";\nimport { AudioStreamFormatImpl } from \"../sdk/Audio/AudioStreamFormat\";\nimport { SpeakerRecognitionModel } from \"../sdk/SpeakerRecognitionModel\";\nimport {\n    CancellationErrorCode,\n    CancellationReason,\n    SpeakerRecognitionResult,\n    SpeakerRecognizer,\n    PropertyCollection,\n    PropertyId,\n    ResultReason,\n    SessionEventArgs,\n} from \"../sdk/Exports\";\nimport {\n    CancellationErrorCodePropertyName,\n    ISpeechConfigAudioDevice,\n    SpeakerResponse,\n    ServiceRecognizerBase,\n} from \"./Exports\";\nimport { IAuthentication } from \"./IAuthentication\";\nimport { IConnectionFactory } from \"./IConnectionFactory\";\nimport { RecognizerConfig } from \"./RecognizerConfig\";\nimport { SpeechConnectionMessage } from \"./SpeechConnectionMessage.Internal\";\n\ninterface SpeakerContext {\n    scenario: string;\n    profileIds: string[];\n    features: {\n        interimResult: string;\n        progressiveDetection: string;\n    };\n}\n\n// eslint-disable-next-line max-classes-per-file\nexport class SpeakerServiceRecognizer extends ServiceRecognizerBase {\n    private privSpeakerRecognizer: SpeakerRecognizer;\n    private privSpeakerAudioSource: IAudioSource;\n    private privResultDeferral: Deferred<SpeakerRecognitionResult>;\n    private privSpeakerModel: SpeakerRecognitionModel;\n\n    public constructor(\n        authentication: IAuthentication,\n        connectionFactory: IConnectionFactory,\n        audioSource: IAudioSource,\n        recognizerConfig: RecognizerConfig,\n        recognizer: SpeakerRecognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);\n        this.privSpeakerRecognizer = recognizer;\n        this.privSpeakerAudioSource = audioSource;\n        this.recognizeSpeaker = (model: SpeakerRecognitionModel): Promise<SpeakerRecognitionResult> => this.recognizeSpeakerOnce(model);\n        this.sendPrePayloadJSONOverride = (): Promise<void> => this.noOp();\n    }\n\n    protected processTypeSpecificMessages(connectionMessage: SpeechConnectionMessage): Promise<boolean> {\n\n        let processed: boolean = false;\n\n        const resultProps: PropertyCollection = new PropertyCollection();\n        if (connectionMessage.messageType === MessageType.Text) {\n            resultProps.setProperty(PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n        }\n\n        switch (connectionMessage.path.toLowerCase()) {\n            case \"speaker.response\":\n                const response: SpeakerResponse = JSON.parse(connectionMessage.textBody) as SpeakerResponse;\n                let result: SpeakerRecognitionResult;\n                if (response.status.statusCode.toLowerCase() !== \"success\") {\n                    result = new SpeakerRecognitionResult(\n                        response,\n                        ResultReason.Canceled,\n                        CancellationErrorCode.ServiceError,\n                        response.status.reason\n                        );\n                } else {\n                    result = new SpeakerRecognitionResult(\n                        response,\n                        ResultReason.RecognizedSpeaker,\n                        );\n                }\n                if (!!this.privResultDeferral) {\n                    this.privResultDeferral.resolve(result);\n                }\n                processed = true;\n                break;\n            default:\n                break;\n        }\n        const defferal = new Deferred<boolean>();\n        defferal.resolve(processed);\n        return defferal.promise;\n    }\n\n    // Cancels recognition.\n    protected cancelRecognition(\n        sessionId: string,\n        requestId: string,\n        cancellationReason: CancellationReason,\n        errorCode: CancellationErrorCode,\n        error: string): void {\n\n        const properties: PropertyCollection = new PropertyCollection();\n        properties.setProperty(CancellationErrorCodePropertyName, CancellationErrorCode[errorCode]);\n\n        if (!!this.privResultDeferral) {\n            const result: SpeakerRecognitionResult = new SpeakerRecognitionResult(\n                {\n                    scenario: this.privSpeakerModel.scenario,\n                    status: { statusCode: error, reason: error }\n                },\n                ResultReason.Canceled,\n                errorCode,\n                error\n                );\n            try {\n                this.privResultDeferral.resolve(result);\n            } catch (error) {\n                this.privResultDeferral.reject(error as string);\n            }\n        }\n    }\n\n    public async recognizeSpeakerOnce(model: SpeakerRecognitionModel): Promise<SpeakerRecognitionResult> {\n        this.privSpeakerModel = model;\n        this.voiceProfileType = model.scenario;\n        if (!this.privResultDeferral) {\n            this.privResultDeferral = new Deferred<SpeakerRecognitionResult>();\n        }\n        this.privRequestSession.startNewRecognition();\n        this.privRequestSession.listenForServiceTelemetry(this.privSpeakerAudioSource.events);\n\n        this.privRecognizerConfig.parameters.setProperty(PropertyId.Speech_SessionId, this.privRequestSession.sessionId);\n\n        // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n        const conPromise: Promise<IConnection> = this.connectImpl();\n\n        const preAudioPromise: Promise<void> = this.sendPreAudioMessages(this.extractSpeakerContext(model));\n\n        const node: IAudioStreamNode = await this.privSpeakerAudioSource.attach(this.privRequestSession.audioNodeId);\n        const format: AudioStreamFormatImpl = await this.privSpeakerAudioSource.format;\n        const deviceInfo: ISpeechConfigAudioDevice = await this.privSpeakerAudioSource.deviceInfo;\n\n        const audioNode = new ReplayableAudioNode(node, format.avgBytesPerSec);\n        await this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);\n\n        this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };\n\n        try {\n            await conPromise;\n            await preAudioPromise;\n        } catch (err) {\n            this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, CancellationReason.Error, CancellationErrorCode.ConnectionFailure, err as string);\n        }\n\n        const sessionStartEventArgs: SessionEventArgs = new SessionEventArgs(this.privRequestSession.sessionId);\n\n        if (!!this.privRecognizer.sessionStarted) {\n            this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);\n        }\n\n        void this.receiveMessage();\n        const audioSendPromise = this.sendAudio(audioNode);\n\n        // /* eslint-disable no-empty */\n        audioSendPromise.then((): void => { /* add? return true;*/ }, (error: string): void => {\n            this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, CancellationReason.Error, CancellationErrorCode.RuntimeError, error);\n        });\n\n        return this.privResultDeferral.promise;\n    }\n\n    private async sendPreAudioMessages(context: SpeakerContext): Promise<void> {\n        const connection: IConnection = await this.fetchConnection();\n        await this.sendSpeakerRecognition(connection, context);\n        // await this.sendWaveHeader(connection);\n    }\n\n    private async sendSpeakerRecognition(connection: IConnection, context: SpeakerContext): Promise<void> {\n        const speakerContextJson = JSON.stringify(context);\n        return connection.send(new SpeechConnectionMessage(\n            MessageType.Text,\n            \"speaker.context\",\n            this.privRequestSession.requestId,\n            \"application/json; charset=utf-8\",\n            speakerContextJson));\n    }\n\n    private extractSpeakerContext(model: SpeakerRecognitionModel): SpeakerContext {\n        return {\n            features: {\n                interimResult: \"enabled\",\n                progressiveDetection: \"disabled\",\n            },\n            profileIds: model.profileIds,\n            scenario: model.scenario,\n        };\n    }\n}\n"]}