{"version":3,"sources":["src/common.speech/ConversationServiceRecognizer.ts"],"names":[],"mappings":"AAAA,OAAO,EAAE,YAAY,EAAE,MAAM,mBAAmB,CAAC;AACjD,OAAO,EACH,qBAAqB,EACrB,kBAAkB,EAIlB,UAAU,EAEV,uBAAuB,EAC1B,MAAM,gBAAgB,CAAC;AACxB,OAAO,EAGH,eAAe,EACf,kBAAkB,EAGlB,gBAAgB,EAChB,qBAAqB,EAGxB,MAAM,WAAW,CAAC;AACnB,OAAO,EAAE,uBAAuB,EAAE,MAAM,oCAAoC,CAAC;AAE7E,qBAAa,6BAA8B,SAAQ,qBAAqB;gBAGhE,cAAc,EAAE,eAAe,EAC/B,iBAAiB,EAAE,kBAAkB,EACrC,WAAW,EAAE,YAAY,EACzB,gBAAgB,EAAE,gBAAgB,EAClC,UAAU,EAAE,UAAU;IAM1B,SAAS,CAAC,2BAA2B,CAAC,iBAAiB,EAAE,uBAAuB,GAAG,OAAO,CAAC,OAAO,CAAC;IAKnG,SAAS,CAAC,wBAAwB,CAAC,MAAM,EAAE,uBAAuB,EAAE,MAAM,EAAE,MAAM,EAAE,SAAS,EAAE,MAAM,GAAG,IAAI;IAO5G,SAAS,CAAC,yBAAyB,CAAC,MAAM,EAAE,uBAAuB,EAAE,QAAQ,EAAE,MAAM,EAAE,SAAS,EAAE,MAAM,GAAG,IAAI;cAO/F,qBAAqB,CAAC,iBAAiB,EAAE,uBAAuB,GAAG,OAAO,CAAC,OAAO,CAAC;IAsBnG,SAAS,CAAC,iBAAiB,CACvB,SAAS,EAAE,MAAM,EACjB,SAAS,EAAE,MAAM,EACjB,kBAAkB,EAAE,kBAAkB,EACtC,SAAS,EAAE,qBAAqB,EAChC,KAAK,EAAE,MAAM,GAAG,IAAI;cASR,kBAAkB,CAAC,QAAQ,EAAE,MAAM,GAAG,OAAO,CAAC,IAAI,CAAC;IA8DnE,SAAS,CAAC,sBAAsB,CAAC,QAAQ,EAAE,MAAM,GAAG,IAAI;CAuB3D","file":"ConversationServiceRecognizer.d.ts","sourcesContent":["import { IAudioSource } from \"../common/Exports\";\nimport {\n    CancellationErrorCode,\n    CancellationReason,\n    OutputFormat,\n    PropertyCollection,\n    PropertyId,\n    Recognizer,\n    ResultReason,\n    SpeechRecognitionResult\n} from \"../sdk/Exports\";\nimport {\n    DetailedSpeechPhrase,\n    EnumTranslation,\n    IAuthentication,\n    IConnectionFactory,\n    OutputFormatPropertyName,\n    RecognitionStatus,\n    RecognizerConfig,\n    ServiceRecognizerBase,\n    SimpleSpeechPhrase,\n    SpeechHypothesis\n} from \"./Exports\";\nimport { SpeechConnectionMessage } from \"./SpeechConnectionMessage.Internal\";\n\nexport class ConversationServiceRecognizer extends ServiceRecognizerBase {\n\n    public constructor(\n        authentication: IAuthentication,\n        connectionFactory: IConnectionFactory,\n        audioSource: IAudioSource,\n        recognizerConfig: RecognizerConfig,\n        recognizer: Recognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);\n        this.handleSpeechPhraseMessage = async (textBody: string): Promise<void> => this.handleSpeechPhrase(textBody);\n        this.handleSpeechHypothesisMessage = (textBody: string): void => this.handleSpeechHypothesis(textBody);\n    }\n\n    protected processTypeSpecificMessages(connectionMessage: SpeechConnectionMessage): Promise<boolean> {\n        void connectionMessage;\n        return;\n    }\n\n    protected handleRecognizedCallback(result: SpeechRecognitionResult, offset: number, sessionId: string): void {\n        void result;\n        void offset;\n        void sessionId;\n        return;\n    }\n\n    protected handleRecognizingCallback(result: SpeechRecognitionResult, duration: number, sessionId: string): void {\n        void result;\n        void duration;\n        void sessionId;\n        return;\n    }\n\n    protected async processSpeechMessages(connectionMessage: SpeechConnectionMessage): Promise<boolean> {\n        let processed: boolean = false;\n        switch (connectionMessage.path.toLowerCase()) {\n            case \"speech.hypothesis\":\n            case \"speech.fragment\":\n                if (!!this.handleSpeechHypothesisMessage) {\n                    this.handleSpeechHypothesisMessage(connectionMessage.textBody);\n                }\n                processed = true;\n                break;\n            case \"speech.phrase\":\n                if (!!this.handleSpeechPhraseMessage) {\n                    await this.handleSpeechPhraseMessage(connectionMessage.textBody);\n                }\n                processed = true;\n                break;\n            default:\n                break;\n        }\n        return processed;\n    }\n\n    protected cancelRecognition(\n        sessionId: string,\n        requestId: string,\n        cancellationReason: CancellationReason,\n        errorCode: CancellationErrorCode,\n        error: string): void {\n            // Implementing to allow inheritance\n            void sessionId;\n            void requestId;\n            void cancellationReason;\n            void errorCode;\n            void error;\n        }\n\n    protected async handleSpeechPhrase(textBody: string): Promise<void> {\n\n        const simple: SimpleSpeechPhrase = SimpleSpeechPhrase.fromJSON(textBody);\n        const resultReason: ResultReason = EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);\n        let result: SpeechRecognitionResult;\n        const resultProps: PropertyCollection = new PropertyCollection();\n        resultProps.setProperty(PropertyId.SpeechServiceResponse_JsonResult, textBody);\n        const simpleOffset = simple.Offset + this.privRequestSession.currentTurnAudioOffset;\n        let offset = simpleOffset;\n\n        this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);\n\n        if (ResultReason.Canceled === resultReason) {\n            const cancelReason: CancellationReason = EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);\n            const cancellationErrorCode: CancellationErrorCode = EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);\n\n            await this.cancelRecognitionLocal(\n                cancelReason,\n                cancellationErrorCode,\n                EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));\n\n        } else {\n            if (!(this.privRequestSession.isSpeechEnded && resultReason === ResultReason.NoMatch && simple.RecognitionStatus !== RecognitionStatus.InitialSilenceTimeout)) {\n                if (this.privRecognizerConfig.parameters.getProperty(OutputFormatPropertyName) === OutputFormat[OutputFormat.Simple]) {\n                    result = new SpeechRecognitionResult(\n                        this.privRequestSession.requestId,\n                        resultReason,\n                        simple.DisplayText,\n                        simple.Duration,\n                        simpleOffset,\n                        simple.Language,\n                        simple.LanguageDetectionConfidence,\n                        simple.SpeakerId,\n                        undefined,\n                        textBody,\n                        resultProps);\n                } else {\n                    const detailed: DetailedSpeechPhrase = DetailedSpeechPhrase.fromJSON(textBody);\n                    const totalOffset: number = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;\n                    const offsetCorrectedJson: string = detailed.getJsonWithCorrectedOffsets(totalOffset);\n\n                    result = new SpeechRecognitionResult(\n                        this.privRequestSession.requestId,\n                        resultReason,\n                        detailed.Text,\n                        detailed.Duration,\n                        totalOffset,\n                        detailed.Language,\n                        detailed.LanguageDetectionConfidence,\n                        detailed.SpeakerId,\n                        undefined,\n                        offsetCorrectedJson,\n                        resultProps);\n\n                        offset = result.offset;\n                }\n\n                this.handleRecognizedCallback(result, offset, this.privRequestSession.sessionId);\n            }\n        }\n    }\n\n    protected handleSpeechHypothesis(textBody: string): void {\n        const hypothesis: SpeechHypothesis = SpeechHypothesis.fromJSON(textBody);\n        const offset: number = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;\n        const resultProps: PropertyCollection = new PropertyCollection();\n        resultProps.setProperty(PropertyId.SpeechServiceResponse_JsonResult, textBody);\n\n        const result = new SpeechRecognitionResult(\n            this.privRequestSession.requestId,\n            ResultReason.RecognizingSpeech,\n            hypothesis.Text,\n            hypothesis.Duration,\n            offset,\n            hypothesis.Language,\n            hypothesis.LanguageDetectionConfidence,\n            hypothesis.SpeakerId,\n            undefined,\n            textBody,\n            resultProps);\n\n        this.privRequestSession.onHypothesis(offset);\n\n        this.handleRecognizingCallback(result, hypothesis.Duration, this.privRequestSession.sessionId);\n    }\n}\n"]}