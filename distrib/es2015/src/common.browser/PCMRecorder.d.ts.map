{"version":3,"sources":["src/common.browser/PCMRecorder.ts"],"names":[],"mappings":"AAGA,OAAO,EAAkB,MAAM,EAAE,MAAM,mBAAmB,CAAC;AAC3D,OAAO,EAAE,SAAS,EAAE,MAAM,aAAa,CAAC;AAExC,qBAAa,WAAY,YAAW,SAAS;IACzC,OAAO,CAAC,kBAAkB,CAAkB;IAC5C,OAAO,CAAC,yBAAyB,CAAS;IAC1C,OAAO,CAAC,sBAAsB,CAAU;gBAErB,kBAAkB,EAAE,OAAO;IAIvC,MAAM,CAAC,OAAO,EAAE,YAAY,EAAE,WAAW,EAAE,WAAW,EAAE,YAAY,EAAE,MAAM,CAAC,WAAW,CAAC,GAAG,IAAI;IA6GhG,qBAAqB,CAAC,OAAO,EAAE,YAAY,GAAG,IAAI;IAgBlD,aAAa,CAAC,GAAG,EAAE,MAAM,GAAG,IAAI;CAG1C","file":"PCMRecorder.d.ts","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nimport { RiffPcmEncoder, Stream } from \"../common/Exports\";\nimport { IRecorder } from \"./IRecorder\";\n\nexport class PcmRecorder implements IRecorder {\n    private privMediaResources: IMediaResources;\n    private privSpeechProcessorScript: string; // speech-processor.js Url\n    private privStopInputOnRelease: boolean;\n\n    public constructor(stopInputOnRelease: boolean) {\n        this.privStopInputOnRelease = stopInputOnRelease;\n    }\n\n    public record(context: AudioContext, mediaStream: MediaStream, outputStream: Stream<ArrayBuffer>): void {\n        const desiredSampleRate = 16000;\n\n        const waveStreamEncoder = new RiffPcmEncoder(context.sampleRate, desiredSampleRate);\n\n        const micInput = context.createMediaStreamSource(mediaStream);\n\n        const attachScriptProcessor = (): void => {\n            // eslint-disable-next-line @typescript-eslint/explicit-function-return-type\n            const scriptNode = (() => {\n                let bufferSize = 0;\n                try {\n                    return context.createScriptProcessor(bufferSize, 1, 1);\n                } catch (error) {\n                    // Webkit (<= version 31) requires a valid bufferSize.\n                    bufferSize = 2048;\n                    let audioSampleRate = context.sampleRate;\n                    while (bufferSize < 16384 && audioSampleRate >= (2 * desiredSampleRate)) {\n                        bufferSize <<= 1;\n                        audioSampleRate >>= 1;\n                    }\n                    return context.createScriptProcessor(bufferSize, 1, 1);\n                }\n            })();\n            scriptNode.onaudioprocess = (event: AudioProcessingEvent): void => {\n                const inputFrame = event.inputBuffer.getChannelData(0);\n\n                if (outputStream && !outputStream.isClosed) {\n                    const waveFrame = waveStreamEncoder.encode(inputFrame);\n                    if (!!waveFrame) {\n                        outputStream.writeStreamChunk({\n                            buffer: waveFrame,\n                            isEnd: false,\n                            timeReceived: Date.now(),\n                        });\n                    }\n                }\n            };\n            micInput.connect(scriptNode);\n            scriptNode.connect(context.destination);\n            this.privMediaResources = {\n                scriptProcessorNode: scriptNode,\n                source: micInput,\n                stream: mediaStream,\n            };\n        };\n\n        // https://webaudio.github.io/web-audio-api/#audioworklet\n        // Using AudioWorklet to improve audio quality and avoid audio glitches due to blocking the UI thread\n\n        if (!!context.audioWorklet) {\n            if (!this.privSpeechProcessorScript) {\n                const workletScript = `class SP extends AudioWorkletProcessor {\n                    constructor(options) {\n                      super(options);\n                    }\n                    process(inputs, outputs) {\n                      const input = inputs[0];\n                      const output = [];\n                      for (let channel = 0; channel < input.length; channel += 1) {\n                        output[channel] = input[channel];\n                      }\n                      this.port.postMessage(output[0]);\n                      return true;\n                    }\n                  }\n                  registerProcessor('speech-processor', SP);`;\n                const blob = new Blob([workletScript], { type: \"application/javascript; charset=utf-8\" });\n                this.privSpeechProcessorScript = URL.createObjectURL(blob);\n            }\n\n            context.audioWorklet\n                .addModule(this.privSpeechProcessorScript)\n                .then((): void => {\n                    const workletNode = new AudioWorkletNode(context, \"speech-processor\");\n                    workletNode.port.onmessage = (ev: MessageEvent): void => {\n                        const inputFrame: Float32Array = ev.data as Float32Array;\n\n                        if (outputStream && !outputStream.isClosed) {\n                            const waveFrame = waveStreamEncoder.encode(inputFrame);\n                            if (!!waveFrame) {\n                                outputStream.writeStreamChunk({\n                                    buffer: waveFrame,\n                                    isEnd: false,\n                                    timeReceived: Date.now(),\n                                });\n                            }\n                        }\n                    };\n                    micInput.connect(workletNode);\n                    workletNode.connect(context.destination);\n                    this.privMediaResources = {\n                        scriptProcessorNode: workletNode,\n                        source: micInput,\n                        stream: mediaStream,\n                    };\n                })\n                .catch((): void => {\n                    attachScriptProcessor();\n                });\n        } else {\n            try {\n                attachScriptProcessor();\n            } catch (err) {\n                throw new Error(`Unable to start audio worklet node for PCMRecorder: ${err as string}`);\n            }\n        }\n    }\n\n    public releaseMediaResources(context: AudioContext): void {\n        if (this.privMediaResources) {\n            if (this.privMediaResources.scriptProcessorNode) {\n                this.privMediaResources.scriptProcessorNode.disconnect(context.destination);\n                this.privMediaResources.scriptProcessorNode = null;\n            }\n            if (this.privMediaResources.source) {\n                this.privMediaResources.source.disconnect();\n                if (this.privStopInputOnRelease) {\n                    this.privMediaResources.stream.getTracks().forEach((track: MediaStreamTrack): void => track.stop());\n                }\n                this.privMediaResources.source = null;\n            }\n        }\n    }\n\n    public setWorkletUrl(url: string): void {\n        this.privSpeechProcessorScript = url;\n    }\n}\n\ninterface IMediaResources {\n    source: MediaStreamAudioSourceNode;\n    scriptProcessorNode: ScriptProcessorNode | AudioWorkletNode;\n    stream: MediaStream;\n}\n"]}