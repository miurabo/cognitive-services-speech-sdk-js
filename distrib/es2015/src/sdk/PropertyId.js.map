{"version":3,"sources":["src/sdk/PropertyId.ts"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;AAElC;;;GAGG;AACH,MAAM,CAAN,IAAY,UA6dX;AA7dD,WAAY,UAAU;IAElB;;;;;;OAMG;IACH,yFAA+B,CAAA;IAE/B;;;;;;OAMG;IACH,mGAAgC,CAAA;IAEhC;;;;;OAKG;IACH,+FAA8B,CAAA;IAE9B;;;;;;OAMG;IACH,mGAAgC,CAAA;IAEhC;;;OAGG;IACH,iGAA+B,CAAA;IAE/B;;;;;;OAMG;IACH,uGAAkC,CAAA;IAElC;;;;;;OAMG;IACH,+HAA8C,CAAA;IAE9C;;;;;;OAMG;IACH,mHAAwC,CAAA;IAExC;;;OAGG;IACH,yHAA2C,CAAA;IAE3C;;;;OAIG;IACH,2GAAoC,CAAA;IAEpC;;;;;OAKG;IACH,8GAAqC,CAAA;IAErC;;;;;OAKG;IACH,sGAAiC,CAAA;IAEjC;;;;;OAKG;IACH,8GAAqC,CAAA;IAErC;;;;;OAKG;IACH,8GAAqC,CAAA;IAErC;;;;OAIG;IACH,oGAAgC,CAAA;IAEhC;;;;;OAKG;IACH,4GAAoC,CAAA;IAEpC;;;;;;OAMG;IACH,oEAAgB,CAAA;IAEhB;;;OAGG;IACH,8GAAqC,CAAA;IAErC;;;OAGG;IACH,wGAAkC,CAAA;IAElC;;;OAGG;IACH,sHAAyC,CAAA;IAEzC;;;;OAIG;IACH,sIAAiD,CAAA;IAEjD;;;;;OAKG;IACH,4IAAoD,CAAA;IAEpD;;;OAGG;IACH,8IAAqD,CAAA;IAErD;;;OAGG;IACH,oGAAgC,CAAA;IAEhC;;;;OAIG;IACH,gHAAsC,CAAA;IAEtC;;;OAGG;IACH,wFAA0B,CAAA;IAE1B;;;OAGG;IACH,gGAA8B,CAAA;IAE9B;;;OAGG;IACH,gHAAsC,CAAA;IAEtC;;;OAGG;IACH,kIAA+C,CAAA;IAE/C;;;;OAIG;IACH,0FAA2B,CAAA;IAE3B;;;OAGG;IACH,kIAA+C,CAAA;IAE/C;;;OAGG;IACH,0HAA2C,CAAA;IAE3C;;;;;;;;;;;;OAYG;IACH,0GAAmC,CAAA;IAEnC;;;;;;OAMG;IACH,wHAA0C,CAAA;IAE1C;;;;;;QAMI;IACJ,gHAAsC,CAAA;IAEtC;;;OAGG;IACH,wIAAkD,CAAA;IAElD;;;;OAIG;IACH,8GAAqC,CAAA;IAErC;;;;OAIG;IACH,8GAAqC,CAAA;IAErC;;;;OAIG;IACH,wHAA0C,CAAA;IAE1C;;;OAGG;IACH,oIAAgD,CAAA;IAEhD;;;OAGG;IACH,wIAAkD,CAAA;IAElD;;;OAGG;IACH,oHAAwC,CAAA;IAExC;;;OAGG;IACH,0JAA2D,CAAA;IAE3D;;;;OAIG;IACH,sHAAyC,CAAA;IAEzC;;;;OAIG;IACH,oIAAgD,CAAA;IAEhD;;;;OAIG;IACH,8HAA6C,CAAA;IAE7C;;;OAGG;IACH,wFAA0B,CAAA;IAE1B;;;OAGG;IACH,kFAAuB,CAAA;IAEvB;;;OAGG;IACH,4GAAoC,CAAA;IAEpC;;;OAGG;IACH,4EAAoB,CAAA;IAEpB;;;OAGG;IACH,4FAA4B,CAAA;IAE5B;;;OAGG;IACH,oHAAwC,CAAA;IAExC;;;;OAIG;IACH,8GAAqC,CAAA;IAErC;;;;OAIG;IACH,oHAAwC,CAAA;IAExC;;;;OAIG;IACH,oGAAgC,CAAA;IAEhC;;;OAGG;IACH,4FAA4B,CAAA;IAE5B;;OAEG;IACH,0FAA2B,CAAA;IAE3B;;;OAGG;IACH,0FAA2B,CAAA;IAE3B;;;OAGG;IACH,4GAAoC,CAAA;IAEpC;;;;OAIG;IACH,4FAA4B,CAAA;IAE5B;;;;;;OAMG;IACH,8GAAqC,CAAA;IAErC;;;;OAIG;IACH,8GAAqC,CAAA;IAErC;;;;OAIG;IACH,0GAAmC,CAAA;IAEnC;;;;;;OAMG;IACH,4GAAoC,CAAA;IAEpC;;;;OAIG;IACH,4FAA4B,CAAA;IAE5B;;;;OAIG;IACH,gGAA8B,CAAA;IAE9B;;;OAGG;IACH,gGAA8B,CAAA;AAClC,CAAC,EA7dW,UAAU,KAAV,UAAU,QA6drB","file":"PropertyId.js","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines speech property ids.\n * @class PropertyId\n */\nexport enum PropertyId {\n\n    /**\n     * The Cognitive Services Speech Service subscription Key. If you are using an intent recognizer, you need to\n     * specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't\n     * have to use this property directly.\n     * Instead, use [[SpeechConfig.fromSubscription]].\n     * @member PropertyId.SpeechServiceConnection_Key\n     */\n    SpeechServiceConnection_Key = 0,\n\n    /**\n     * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't\n     * have to use this property directly.\n     * Instead, use [[SpeechConfig.fromEndpoint]].\n     * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.\n     * @member PropertyId.SpeechServiceConnection_Endpoint\n     */\n    SpeechServiceConnection_Endpoint,\n\n    /**\n     * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to\n     * use this property directly.\n     * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].\n     * @member PropertyId.SpeechServiceConnection_Region\n     */\n    SpeechServiceConnection_Region,\n\n    /**\n     * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,\n     * you shouldn't have to use this property directly.\n     * Instead, use [[SpeechConfig.fromAuthorizationToken]], [[SpeechRecognizer.authorizationToken]],\n     * [[IntentRecognizer.authorizationToken]], [[TranslationRecognizer.authorizationToken]], [[SpeakerRecognizer.authorizationToken]].\n     * @member PropertyId.SpeechServiceAuthorization_Token\n     */\n    SpeechServiceAuthorization_Token,\n\n    /**\n     * The Cognitive Services Speech Service authorization type. Currently unused.\n     * @member PropertyId.SpeechServiceAuthorization_Type\n     */\n    SpeechServiceAuthorization_Type,\n\n    /**\n     * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't\n     * have to use this property directly.\n     * Instead, use [[SpeechConfig.endpointId]].\n     * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.\n     * @member PropertyId.SpeechServiceConnection_EndpointId\n     */\n    SpeechServiceConnection_EndpointId,\n\n    /**\n     * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,\n     * you shouldn't have to use this property directly.\n     * Instead use [[SpeechTranslationConfig.addTargetLanguage]],\n     * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].\n     * @member PropertyId.SpeechServiceConnection_TranslationToLanguages\n     */\n    SpeechServiceConnection_TranslationToLanguages,\n\n    /**\n     * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this\n     * property directly.\n     * Instead, use [[SpeechTranslationConfig.voiceName]].\n     * NOTE: Valid voice names can be found <a href=\"https://aka.ms/csspeech/voicenames\">here</a>.\n     * @member PropertyId.SpeechServiceConnection_TranslationVoice\n     */\n    SpeechServiceConnection_TranslationVoice,\n\n    /**\n     * Translation features.\n     * @member PropertyId.SpeechServiceConnection_TranslationFeatures\n     */\n    SpeechServiceConnection_TranslationFeatures,\n\n    /**\n     * The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.\n     * Instead, use [[LanguageUnderstandingModel]].\n     * @member PropertyId.SpeechServiceConnection_IntentRegion\n     */\n    SpeechServiceConnection_IntentRegion,\n\n    /**\n     * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    SpeechServiceConnection_ProxyHostName,\n\n    /**\n     * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    SpeechServiceConnection_ProxyPort,\n\n    /**\n     * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    SpeechServiceConnection_ProxyUserName,\n\n    /**\n     * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    SpeechServiceConnection_ProxyPassword,\n\n    /**\n     * The Cognitive Services Speech Service recognition Mode. Can be \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\".\n     * This property is intended to be read-only. The SDK is using it internally.\n     * @member PropertyId.SpeechServiceConnection_RecoMode\n     */\n    SpeechServiceConnection_RecoMode,\n\n    /**\n     * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property\n     * directly.\n     * Instead, use [[SpeechConfig.speechRecognitionLanguage]].\n     * @member PropertyId.SpeechServiceConnection_RecoLanguage\n     */\n    SpeechServiceConnection_RecoLanguage,\n\n    /**\n     * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream\n     * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this\n     * property directly.\n     * Instead use [[SessionEventArgs.sessionId]].\n     * @member PropertyId.Speech_SessionId\n     */\n    Speech_SessionId,\n\n    /**\n     * The spoken language to be synthesized (e.g. en-US)\n     * @member PropertyId.SpeechServiceConnection_SynthLanguage\n     */\n    SpeechServiceConnection_SynthLanguage,\n\n    /**\n     * The name of the TTS voice to be used for speech synthesis\n     * @member PropertyId.SpeechServiceConnection_SynthVoice\n     */\n    SpeechServiceConnection_SynthVoice,\n\n    /**\n     * The string to specify TTS output audio format\n     * @member PropertyId.SpeechServiceConnection_SynthOutputFormat\n     */\n    SpeechServiceConnection_SynthOutputFormat,\n\n    /**\n     * The list of comma separated languages used as possible source languages\n     * Added in version 1.13.0\n     * @member PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages\n     */\n    SpeechServiceConnection_AutoDetectSourceLanguages,\n\n    /**\n     * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have\n     * to use this property directly.\n     * Instead use [[SpeechConfig.outputFormat]].\n     * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse\n     */\n    SpeechServiceResponse_RequestDetailedResultTrueFalse,\n\n    /**\n     * The requested Cognitive Services Speech Service response output profanity level. Currently unused.\n     * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse\n     */\n    SpeechServiceResponse_RequestProfanityFilterTrueFalse,\n\n    /**\n     * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.\n     * @member PropertyId.SpeechServiceResponse_JsonResult\n     */\n    SpeechServiceResponse_JsonResult,\n\n    /**\n     * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to\n     * use this property directly. Instead use [[CancellationDetails.errorDetails]].\n     * @member PropertyId.SpeechServiceResponse_JsonErrorDetails\n     */\n    SpeechServiceResponse_JsonErrorDetails,\n\n    /**\n     * The cancellation reason. Currently unused.\n     * @member PropertyId.CancellationDetails_Reason\n     */\n    CancellationDetails_Reason,\n\n    /**\n     * The cancellation text. Currently unused.\n     * @member PropertyId.CancellationDetails_ReasonText\n     */\n    CancellationDetails_ReasonText,\n\n    /**\n     * The Cancellation detailed text. Currently unused.\n     * @member PropertyId.CancellationDetails_ReasonDetailedText\n     */\n    CancellationDetails_ReasonDetailedText,\n\n    /**\n     * The Language Understanding Service response output (in JSON format). Available via [[IntentRecognitionResult]]\n     * @member PropertyId.LanguageUnderstandingServiceResponse_JsonResult\n     */\n    LanguageUnderstandingServiceResponse_JsonResult,\n\n    /**\n     * The URL string built from speech configuration.\n     * This property is intended to be read-only. The SDK is using it internally.\n     * NOTE: Added in version 1.7.0.\n     */\n    SpeechServiceConnection_Url,\n\n    /**\n     * The initial silence timeout value (in milliseconds) used by the service.\n     * Added in version 1.7.0\n     */\n    SpeechServiceConnection_InitialSilenceTimeoutMs,\n\n    /**\n     * The end silence timeout value (in milliseconds) used by the service.\n     * Added in version 1.7.0\n     */\n    SpeechServiceConnection_EndSilenceTimeoutMs,\n\n    /**\n     * A duration of detected silence, measured in milliseconds, after which speech-to-text will determine a spoken\n     * phrase has ended and generate a final Recognized result. Configuring this timeout may be helpful in situations\n     * where spoken input is significantly faster or slower than usual and default segmentation behavior consistently\n     * yields results that are too long or too short. Segmentation timeout values that are inappropriately high or low\n     * can negatively affect speech-to-text accuracy; this property should be carefully configured and the resulting\n     * behavior should be thoroughly validated as intended.\n     *\n     * For more information about timeout configuration that includes discussion of default behaviors, please visit\n     * https://aka.ms/csspeech/timeouts.\n     *\n     * Added in version 1.21.0.\n     */\n    Speech_SegmentationSilenceTimeoutMs,\n\n    /**\n     * A boolean value specifying whether audio logging is enabled in the service or not.\n     * Audio and content logs are stored either in Microsoft-owned storage, or in your own storage account linked\n     * to your Cognitive Services subscription (Bring Your Own Storage (BYOS) enabled Speech resource).\n     * The logs will be removed after 30 days.\n     * Added in version 1.7.0\n     */\n    SpeechServiceConnection_EnableAudioLogging,\n\n    /**\n     * The speech service connection language identifier mode.\n     * Can be \"AtStart\" (the default), or \"Continuous\". See Language\n     * Identification document https://aka.ms/speech/lid?pivots=programming-language-javascript\n     * for more details.\n     * Added in 1.25.0\n     **/\n    SpeechServiceConnection_LanguageIdMode,\n\n    /**\n     * A string value representing the desired endpoint version to target for Speech Recognition.\n     * Added in version 1.21.0\n     */\n    SpeechServiceConnection_RecognitionEndpointVersion,\n\n    /**\n    /**\n     * A string value the current speaker recognition scenario/mode (TextIndependentIdentification, etc.).\n     * Added in version 1.23.0\n     */\n    SpeechServiceConnection_SpeakerIdMode,\n\n    /**\n     * The requested Cognitive Services Speech Service response output profanity setting.\n     * Allowed values are \"masked\", \"removed\", and \"raw\".\n     * Added in version 1.7.0.\n     */\n    SpeechServiceResponse_ProfanityOption,\n\n    /**\n     * A string value specifying which post processing option should be used by service.\n     * Allowed values are \"TrueText\".\n     * Added in version 1.7.0\n     */\n    SpeechServiceResponse_PostProcessingOption,\n\n    /**\n     * A boolean value specifying whether to include word-level timestamps in the response result.\n     * Added in version 1.7.0\n     */\n    SpeechServiceResponse_RequestWordLevelTimestamps,\n\n    /**\n     * The number of times a word has to be in partial results to be returned.\n     * Added in version 1.7.0\n     */\n    SpeechServiceResponse_StablePartialResultThreshold,\n\n    /**\n     * A string value specifying the output format option in the response result. Internal use only.\n     * Added in version 1.7.0.\n     */\n    SpeechServiceResponse_OutputFormatOption,\n\n    /**\n     * A boolean value to request for stabilizing translation partial results by omitting words in the end.\n     * Added in version 1.7.0.\n     */\n    SpeechServiceResponse_TranslationRequestStablePartialResult,\n\n    /**\n     * A boolean value specifying whether to request WordBoundary events.\n     * @member PropertyId.SpeechServiceResponse_RequestWordBoundary\n     * Added in version 1.21.0.\n     */\n    SpeechServiceResponse_RequestWordBoundary,\n\n    /**\n     * A boolean value specifying whether to request punctuation boundary in WordBoundary Events. Default is true.\n     * @member PropertyId.SpeechServiceResponse_RequestPunctuationBoundary\n     * Added in version 1.21.0.\n     */\n    SpeechServiceResponse_RequestPunctuationBoundary,\n\n    /**\n     * A boolean value specifying whether to request sentence boundary in WordBoundary Events. Default is false.\n     * @member PropertyId.SpeechServiceResponse_RequestSentenceBoundary\n     * Added in version 1.21.0.\n     */\n    SpeechServiceResponse_RequestSentenceBoundary,\n\n    /**\n     * Identifier used to connect to the backend service.\n     * @member PropertyId.Conversation_ApplicationId\n     */\n    Conversation_ApplicationId,\n\n    /**\n     * Type of dialog backend to connect to.\n     * @member PropertyId.Conversation_DialogType\n     */\n    Conversation_DialogType,\n\n    /**\n     * Silence timeout for listening\n     * @member PropertyId.Conversation_Initial_Silence_Timeout\n     */\n    Conversation_Initial_Silence_Timeout,\n\n    /**\n     * From Id to add to speech recognition activities.\n     * @member PropertyId.Conversation_From_Id\n     */\n    Conversation_From_Id,\n\n    /**\n     * ConversationId for the session.\n     * @member PropertyId.Conversation_Conversation_Id\n     */\n    Conversation_Conversation_Id,\n\n    /**\n     * Comma separated list of custom voice deployment ids.\n     * @member PropertyId.Conversation_Custom_Voice_Deployment_Ids\n     */\n    Conversation_Custom_Voice_Deployment_Ids,\n\n    /**\n     * Speech activity template, stamp properties from the template on the activity generated by the service for speech.\n     * @member PropertyId.Conversation_Speech_Activity_Template\n     * Added in version 1.10.0.\n     */\n    Conversation_Speech_Activity_Template,\n\n    /**\n     * Enables or disables the receipt of turn status messages as obtained on the turnStatusReceived event.\n     * @member PropertyId.Conversation_Request_Bot_Status_Messages\n     * Added in version 1.15.0.\n     */\n    Conversation_Request_Bot_Status_Messages,\n\n    /**\n     * Specifies the connection ID to be provided in the Agent configuration message, e.g. a Direct Line token for\n     * channel authentication.\n     * Added in version 1.15.1.\n     */\n    Conversation_Agent_Connection_Id,\n\n    /**\n     * The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.\n     * Instead, use [[SpeechConfig.fromHost]].\n     */\n    SpeechServiceConnection_Host,\n\n    /**\n     * Set the host for service calls to the Conversation Translator REST management and websocket calls.\n     */\n    ConversationTranslator_Host,\n\n    /**\n     * Optionally set the the host's display name.\n     * Used when joining a conversation.\n     */\n    ConversationTranslator_Name,\n\n    /**\n     * Optionally set a value for the X-CorrelationId request header.\n     * Used for troubleshooting errors in the server logs. It should be a valid guid.\n     */\n    ConversationTranslator_CorrelationId,\n\n    /**\n     * Set the conversation token to be sent to the speech service. This enables the\n     * service to service call from the speech service to the Conversation Translator service for relaying\n     * recognitions. For internal use.\n     */\n    ConversationTranslator_Token,\n\n    /**\n     * The reference text of the audio for pronunciation evaluation.\n     * For this and the following pronunciation assessment parameters, see\n     * https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PronunciationAssessment_ReferenceText,\n\n    /**\n     * The point system for pronunciation score calibration (FivePoint or HundredMark).\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PronunciationAssessment_GradingSystem,\n\n    /**\n     * The pronunciation evaluation granularity (Phoneme, Word, or FullText).\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PronunciationAssessment_Granularity,\n\n    /**\n     * Defines if enable miscue calculation.\n     * With this enabled, the pronounced words will be compared to the reference text,\n     * and will be marked with omission/insertion based on the comparison. The default setting is False.\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PronunciationAssessment_EnableMiscue,\n\n    /**\n     * The json string of pronunciation assessment parameters\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PronunciationAssessment_Json,\n\n    /**\n     * Pronunciation assessment parameters.\n     * This property is intended to be read-only. The SDK is using it internally.\n     * Added in version 1.15.0\n     */\n    PronunciationAssessment_Params,\n\n    /**\n     * Version of Speaker Recognition API to use.\n     * Added in version 1.18.0\n     */\n    SpeakerRecognition_Api_Version\n}\n"]}