{"version":3,"sources":["src/common.speech/SynthesisContext.ts"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;AAGlC,OAAO,EAAE,UAAU,EAAqB,MAAM,gBAAgB,CAAC;AAE/D;;;GAGG;AACH,MAAM,OAAO,gBAAgB;IAKzB,YAAmB,iBAAoC;QAJ/C,gBAAW,GAA+B,EAAE,CAAC;QAKjD,IAAI,CAAC,qBAAqB,GAAG,iBAAiB,CAAC;IACnD,CAAC;IAED;;;;OAIG;IACI,UAAU,CAAC,WAAmB,EAAE,KAAsB;QACzD,IAAI,CAAC,WAAW,CAAC,WAAW,CAAC,GAAG,KAAK,CAAC;IAC1C,CAAC;IAED;;;OAGG;IACH,IAAW,iBAAiB,CAAC,MAA6B;QACtD,IAAI,CAAC,qBAAqB,GAAG,MAAM,CAAC;IACxC,CAAC;IAEM,MAAM;QAET,MAAM,gBAAgB,GAAsB,IAAI,CAAC,qBAAqB,EAAE,CAAC;QACzE,IAAI,CAAC,UAAU,CAAC,WAAW,EAAE,gBAAgB,CAAC,CAAC;QAE/C,OAAO,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;IAC5C,CAAC;IAEO,qBAAqB;QACzB,OAAO;YACH,KAAK,EAAE;gBACH,eAAe,EAAE;oBACb,eAAe,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,qBAAqB,CAAC,eAAe,CAAC;oBAC/D,0BAA0B,EAAE,IAAI,CAAC,qBAAqB,CAAC,UAAU,CAAC,WAAW,CACzE,UAAU,CAAC,gDAAgD,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,qBAAqB,CAAC,YAAY,CAAC,CAAC;oBAC7G,uBAAuB,EAAE,IAAI,CAAC,qBAAqB,CAAC,UAAU,CAAC,WAAW,CACtE,UAAU,CAAC,6CAA6C,EAAE,KAAK,CAAC;oBACpE,iBAAiB,EAAE,IAAI;oBACvB,aAAa,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,qBAAqB,CAAC,cAAc,CAAC;oBAC5D,mBAAmB,EAAE,IAAI,CAAC,qBAAqB,CAAC,UAAU,CAAC,WAAW,CAClE,UAAU,CAAC,yCAAyC,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,qBAAqB,CAAC,YAAY,CAAC,CAAC;iBACzG;gBACD,YAAY,EAAE,IAAI,CAAC,qBAAqB,CAAC,wBAAwB;aACpE;YACD,QAAQ,EAAE;gBACN,aAAa,EAAE,IAAI,CAAC,qBAAqB,CAAC,wBAAwB;aACrE;SACiB,CAAC;IAC3B,CAAC;CACJ","file":"SynthesisContext.js","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nimport { AudioOutputFormatImpl } from \"../sdk/Audio/AudioOutputFormat\";\nimport { PropertyId, SpeechSynthesizer } from \"../sdk/Exports\";\n\n/**\n * Represents the JSON used in the synthesis.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\nexport class SynthesisContext {\n    private privContext: { [section: string]: any } = {};\n    private privSpeechSynthesizer: SpeechSynthesizer;\n    private privAudioOutputFormat: AudioOutputFormatImpl;\n\n    public constructor(speechSynthesizer: SpeechSynthesizer) {\n        this.privSpeechSynthesizer = speechSynthesizer;\n    }\n\n    /**\n     * Adds a section to the synthesis.context object.\n     * @param sectionName Name of the section to add.\n     * @param value JSON serializable object that represents the value.\n     */\n    public setSection(sectionName: string, value: string | object): void {\n        this.privContext[sectionName] = value;\n    }\n\n    /**\n     * Sets the audio output format for synthesis context generation.\n     * @param format {AudioOutputFormatImpl} the output format\n     */\n    public set audioOutputFormat(format: AudioOutputFormatImpl) {\n        this.privAudioOutputFormat = format;\n    }\n\n    public toJSON(): string {\n\n        const synthesisSection: ISynthesisSection = this.buildSynthesisContext();\n        this.setSection(\"synthesis\", synthesisSection);\n\n        return JSON.stringify(this.privContext);\n    }\n\n    private buildSynthesisContext(): ISynthesisSection {\n        return {\n            audio: {\n                metadataOptions: {\n                    bookmarkEnabled: (!!this.privSpeechSynthesizer.bookmarkReached),\n                    punctuationBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(\n                        PropertyId.SpeechServiceResponse_RequestPunctuationBoundary, (!!this.privSpeechSynthesizer.wordBoundary)),\n                    sentenceBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(\n                        PropertyId.SpeechServiceResponse_RequestSentenceBoundary, false),\n                    sessionEndEnabled: true,\n                    visemeEnabled: (!!this.privSpeechSynthesizer.visemeReceived),\n                    wordBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(\n                        PropertyId.SpeechServiceResponse_RequestWordBoundary, (!!this.privSpeechSynthesizer.wordBoundary)),\n                },\n                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,\n            },\n            language: {\n                autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\n            }\n        } as ISynthesisSection;\n    }\n}\n\ninterface ISynthesisSection {\n    audio: {\n        outputFormat: string;\n        metadataOptions: {\n            bookmarkEnabled: boolean;\n            wordBoundaryEnabled: string;\n            punctuationBoundaryEnabled: string;\n            visemeEnabled: boolean;\n            sentenceBoundaryEnabled: string;\n            sessionEndEnabled: boolean;\n        };\n    };\n    language: {\n        autoDetection: boolean;\n    };\n}\n"]}