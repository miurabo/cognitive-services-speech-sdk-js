{"version":3,"sources":["src/common.speech/SynthesisContext.ts"],"names":[],"mappings":"AAGA,OAAO,EAAE,qBAAqB,EAAE,MAAM,gCAAgC,CAAC;AACvE,OAAO,EAAc,iBAAiB,EAAE,MAAM,gBAAgB,CAAC;AAE/D;;;GAGG;AACH,qBAAa,gBAAgB;IACzB,OAAO,CAAC,WAAW,CAAkC;IACrD,OAAO,CAAC,qBAAqB,CAAoB;IACjD,OAAO,CAAC,qBAAqB,CAAwB;gBAElC,iBAAiB,EAAE,iBAAiB;IAIvD;;;;OAIG;IACI,UAAU,CAAC,WAAW,EAAE,MAAM,EAAE,KAAK,EAAE,MAAM,GAAG,MAAM,GAAG,IAAI;IAIpE;;;OAGG;IACH,IAAW,iBAAiB,CAAC,MAAM,EAAE,qBAAqB,EAEzD;IAEM,MAAM,IAAI,MAAM;IAQvB,OAAO,CAAC,qBAAqB;CAqBhC","file":"SynthesisContext.d.ts","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nimport { AudioOutputFormatImpl } from \"../sdk/Audio/AudioOutputFormat\";\nimport { PropertyId, SpeechSynthesizer } from \"../sdk/Exports\";\n\n/**\n * Represents the JSON used in the synthesis.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\nexport class SynthesisContext {\n    private privContext: { [section: string]: any } = {};\n    private privSpeechSynthesizer: SpeechSynthesizer;\n    private privAudioOutputFormat: AudioOutputFormatImpl;\n\n    public constructor(speechSynthesizer: SpeechSynthesizer) {\n        this.privSpeechSynthesizer = speechSynthesizer;\n    }\n\n    /**\n     * Adds a section to the synthesis.context object.\n     * @param sectionName Name of the section to add.\n     * @param value JSON serializable object that represents the value.\n     */\n    public setSection(sectionName: string, value: string | object): void {\n        this.privContext[sectionName] = value;\n    }\n\n    /**\n     * Sets the audio output format for synthesis context generation.\n     * @param format {AudioOutputFormatImpl} the output format\n     */\n    public set audioOutputFormat(format: AudioOutputFormatImpl) {\n        this.privAudioOutputFormat = format;\n    }\n\n    public toJSON(): string {\n\n        const synthesisSection: ISynthesisSection = this.buildSynthesisContext();\n        this.setSection(\"synthesis\", synthesisSection);\n\n        return JSON.stringify(this.privContext);\n    }\n\n    private buildSynthesisContext(): ISynthesisSection {\n        return {\n            audio: {\n                metadataOptions: {\n                    bookmarkEnabled: (!!this.privSpeechSynthesizer.bookmarkReached),\n                    punctuationBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(\n                        PropertyId.SpeechServiceResponse_RequestPunctuationBoundary, (!!this.privSpeechSynthesizer.wordBoundary)),\n                    sentenceBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(\n                        PropertyId.SpeechServiceResponse_RequestSentenceBoundary, false),\n                    sessionEndEnabled: true,\n                    visemeEnabled: (!!this.privSpeechSynthesizer.visemeReceived),\n                    wordBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(\n                        PropertyId.SpeechServiceResponse_RequestWordBoundary, (!!this.privSpeechSynthesizer.wordBoundary)),\n                },\n                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,\n            },\n            language: {\n                autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\n            }\n        } as ISynthesisSection;\n    }\n}\n\ninterface ISynthesisSection {\n    audio: {\n        outputFormat: string;\n        metadataOptions: {\n            bookmarkEnabled: boolean;\n            wordBoundaryEnabled: string;\n            punctuationBoundaryEnabled: string;\n            visemeEnabled: boolean;\n            sentenceBoundaryEnabled: string;\n            sessionEndEnabled: boolean;\n        };\n    };\n    language: {\n        autoDetection: boolean;\n    };\n}\n"]}