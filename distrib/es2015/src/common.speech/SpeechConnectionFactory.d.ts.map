{"version":3,"sources":["src/common.speech/SpeechConnectionFactory.ts"],"names":[],"mappings":"AAWA,OAAO,EACH,WAAW,EAEd,MAAM,mBAAmB,CAAC;AAK3B,OAAO,EACH,qBAAqB,EACxB,MAAM,yBAAyB,CAAC;AACjC,OAAO,EACH,QAAQ,EAER,gBAAgB,EAEnB,MAAM,WAAW,CAAC;AAMnB,qBAAa,uBAAwB,SAAQ,qBAAqB;IAE9D,OAAO,CAAC,QAAQ,CAAC,sBAAsB,CAAkE;IACzG,OAAO,CAAC,QAAQ,CAAC,uBAAuB,CAAmE;IAC3G,OAAO,CAAC,QAAQ,CAAC,oBAAoB,CAAgE;IACrG,OAAO,CAAC,QAAQ,CAAC,YAAY,CAAiC;IAEvD,MAAM,CACT,MAAM,EAAE,gBAAgB,EACxB,QAAQ,EAAE,QAAQ,EAClB,YAAY,CAAC,EAAE,MAAM,GAAG,WAAW;CAyE1C","file":"SpeechConnectionFactory.d.ts","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nimport {\n    ProxyInfo,\n    WebsocketConnection,\n} from \"../common.browser/Exports\";\nimport {\n    ForceDictationPropertyName,\n    OutputFormatPropertyName,\n} from \"../common.speech/Exports\";\nimport {\n    IConnection,\n    IStringDictionary\n} from \"../common/Exports\";\nimport {\n    OutputFormat,\n    PropertyId\n} from \"../sdk/Exports\";\nimport {\n    ConnectionFactoryBase\n} from \"./ConnectionFactoryBase\";\nimport {\n    AuthInfo,\n    RecognitionMode,\n    RecognizerConfig,\n    WebsocketMessageFormatter\n} from \"./Exports\";\nimport { HeaderNames } from \"./HeaderNames\";\nimport {\n    QueryParameterNames\n} from \"./QueryParameterNames\";\n\nexport class SpeechConnectionFactory extends ConnectionFactoryBase {\n\n    private readonly interactiveRelativeUri: string = \"/speech/recognition/interactive/cognitiveservices/v1\";\n    private readonly conversationRelativeUri: string = \"/speech/recognition/conversation/cognitiveservices/v1\";\n    private readonly dictationRelativeUri: string = \"/speech/recognition/dictation/cognitiveservices/v1\";\n    private readonly universalUri: string = \"/speech/universal/v\";\n\n    public create(\n        config: RecognizerConfig,\n        authInfo: AuthInfo,\n        connectionId?: string): IConnection {\n\n        let endpoint: string = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Endpoint, undefined);\n        const region: string = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Region, undefined);\n        const hostSuffix: string = ConnectionFactoryBase.getHostSuffix(region);\n        const host: string = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Host, \"wss://\" + region + \".stt.speech\" + hostSuffix);\n        const queryParams: IStringDictionary<string> = {};\n        const endpointId: string = config.parameters.getProperty(PropertyId.SpeechServiceConnection_EndpointId, undefined);\n        const language: string = config.parameters.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage, undefined);\n\n        if (endpointId) {\n            if (!endpoint || endpoint.search(QueryParameterNames.CustomSpeechDeploymentId) === -1) {\n                queryParams[QueryParameterNames.CustomSpeechDeploymentId] = endpointId;\n            }\n        } else if (language) {\n            if (!endpoint || endpoint.search(QueryParameterNames.Language) === -1) {\n                queryParams[QueryParameterNames.Language] = language;\n            }\n        }\n\n        if (!endpoint || endpoint.search(QueryParameterNames.Format) === -1) {\n            queryParams[QueryParameterNames.Format] = config.parameters.getProperty(OutputFormatPropertyName, OutputFormat[OutputFormat.Simple]).toLowerCase();\n        }\n\n        if (config.autoDetectSourceLanguages !== undefined) {\n            queryParams[QueryParameterNames.EnableLanguageId] = \"true\";\n        }\n\n        this.setCommonUrlParams(config, queryParams, endpoint);\n\n        if (!endpoint) {\n            switch (config.recognitionMode) {\n                case RecognitionMode.Conversation:\n                    if (config.parameters.getProperty(ForceDictationPropertyName, \"false\") === \"true\") {\n                        endpoint = host + this.dictationRelativeUri;\n                    } else {\n                        if (config.recognitionEndpointVersion !== undefined && parseInt(config.recognitionEndpointVersion, 10) > 1) {\n                            endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;\n                        } else {\n                            endpoint = host + this.conversationRelativeUri;\n                        }\n                    }\n                    break;\n                case RecognitionMode.Dictation:\n                    endpoint = host + this.dictationRelativeUri;\n                    break;\n                default:\n                    if (config.recognitionEndpointVersion !== undefined && parseInt(config.recognitionEndpointVersion, 10) > 1) {\n                        endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;\n                    } else {\n                        endpoint = host + this.interactiveRelativeUri; // default is interactive\n                    }\n                    break;\n            }\n        }\n\n        const headers: IStringDictionary<string> = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[HeaderNames.ConnectionId] = connectionId;\n\n        const enableCompression: boolean = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n\n        const webSocketConnection = new WebsocketConnection(endpoint, queryParams, headers, new WebsocketMessageFormatter(), ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n\n        // Set the value of SpeechServiceConnection_Url to webSocketConnection.uri (and not to `endpoint`), since this value is the final\n        // URI that was used to make the connection (including query parameters).\n        const uri: string = webSocketConnection.uri;\n        config.parameters.setProperty(PropertyId.SpeechServiceConnection_Url, uri);\n\n        return webSocketConnection;\n    }\n}\n"]}